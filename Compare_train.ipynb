{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb03265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import datasets\n",
    "import albumentations as A\n",
    "from data import custum_collate\n",
    "import numpy as np\n",
    "import glob, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import albumentations.pytorch\n",
    "import utility\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import os\n",
    "import random\n",
    "from yolox.exp import Exp\n",
    "from yolox.utils import postprocess,crop_mask\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.data as data_utils\n",
    "import datetime\n",
    "from shutil import copyfile\n",
    "import time\n",
    "import modules.evaluation as evaluate\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3377fce-f37b-4197-b41e-95ba21123ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export NCCL_P2P_DISABLE=1\n",
    "!export NCCL_IB_GID_INDEX=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc884b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****TRIAL:   0\n",
      "dataset length :  14306 14306\n",
      "dataset length :  3264 3264\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/2023-09-27-14-32-48_val/checkpoints/last.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 81\u001b[0m\n\u001b[1;32m     73\u001b[0m model \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mget_model()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m#ckpt = torch.load('/home/etri/road-dataset/Track_YOLOX/last.ckpt')\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#model = utility.load_my_state_dict(model,ckpt[\"state_dict\"],legacy=True)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#ckpt = torch.load('/home/etri/road-dataset/Mask_YOLOX/yolox_l.pth', map_location='cpu')\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#model = utility.load_my_state_dict(model,ckpt[\"model\"])\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./output/2023-09-27-14-32-48_val/checkpoints/last.pth.tar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m model \u001b[38;5;241m=\u001b[39m utility\u001b[38;5;241m.\u001b[39mload_my_state_dict(model,ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     84\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/2023-09-27-14-32-48_val/checkpoints/last.pth.tar'"
     ]
    }
   ],
   "source": [
    "purpose = '_val'\n",
    "fold = 1\n",
    "reset_aug = False\n",
    "for trial in range(1):\n",
    "    print(\"*****TRIAL:  \", trial)\n",
    "    #--------------Base Param------------\n",
    "    w_h = [1280, 480]\n",
    "    BATCH_SIZE = 32\n",
    "    num_workers =8\n",
    "    file_root = '/home/user/Dataset/ETRI_Dataset/'\n",
    "    #--------------Base Param------------\n",
    "    #--------------Class Param------------\n",
    "    all_classes =  ['Ped', 'Cyc', 'Mobike', 'Car', 'Bus', 'Cone', 'TL','VehLane', 'OutgoLane', 'MiddleLane', 'IncomLane',  'Pav', 'Jun', 'Xing_L', 'BusStop', 'Parking_L','Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Blocking', 'Informing', 'Brake', 'Stop', 'IncatLft',\n",
    "                       'IncatRht', 'HazLit', 'HeadingLft', 'HeadingRht', 'Parking', 'EmVeh', 'School', 'Control', 'Xing']\n",
    "    len_class = len(all_classes)\n",
    "    agent_classes =  ['Ped', 'Cyc', 'Mobike', 'Car', 'Bus', 'Cone', 'TL']\n",
    "    loc_classes =  ['VehLane', 'OutgoLane', 'MiddleLane', 'IncomLane',  'Pav', 'Jun', 'Xing_L', 'BusStop', 'Parking_L']\n",
    "    action_classes =  ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Blocking', 'Informing', 'Brake', 'Stop', 'IncatLft',\n",
    "                       'IncatRht', 'HazLit', 'HeadingLft', 'HeadingRht', 'Parking', 'EmVeh', 'School', 'Control', 'Xing']\n",
    "    class_nums = [len(agent_classes), len(loc_classes), len(action_classes)]\n",
    "    #--------------Class Param------------\n",
    "\n",
    "    #--------------Learning Rate Param------------\n",
    "    T_0=50# Initial Cycle Length\n",
    "    T_mult=1 # Cycle Length multiplier\n",
    "    eta_max=1e-4 # Max LR\n",
    "    T_up=5  # WarmUp Length\n",
    "    gamma=0.2 # LR reducer\n",
    "\n",
    "    start_epoch =0\n",
    "    num_epochs =101\n",
    "    best_acc = -1\n",
    "\n",
    "    #--------------Learning Rate Param------------\n",
    "    #Train transfrom + Augmentations\n",
    "\n",
    "    train_transform =  A.Compose(\n",
    "        [\n",
    "         \n",
    "         A.RandomSizedBBoxSafeCrop (width=w_h[0],height=w_h[1],erosion_rate=0.3,p=0.7),\n",
    "             \n",
    "         #A.Resize(width=w_h[0],height=w_h[1],p=1),\n",
    "         A.OneOf([\n",
    "             A.Sharpen(p=0.5),\n",
    "             A.AdvancedBlur(p=0.5),\n",
    "         ],p=0.66),\n",
    "         A.RandomBrightnessContrast(p=0.5),\n",
    "\n",
    "        A.Normalize(mean=(0,0,0),std=(1,1,1)),\n",
    "        A.pytorch.transforms.ToTensorV2()],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids']),\n",
    "    )\n",
    "\n",
    "\n",
    "    train_dataset = datasets.Infra_dataset(train=True,class_nums = class_nums,transform=train_transform,file_root = file_root,fold=fold)\n",
    "    train_data_loader = data_utils.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers,collate_fn=custum_collate, pin_memory=True, drop_last=True)\n",
    "\n",
    "    #Val transfrom + Augmentations\n",
    "\n",
    "    val_transform =A.Compose(\n",
    "        [\n",
    "        A.Normalize(mean=(0,0,0),std=(1,1,1)),\n",
    "        #A.Normalize(),\n",
    "        A.pytorch.transforms.ToTensorV2()],\n",
    "        bbox_params=A.BboxParams(format='albumentations', label_fields=['category_ids']),\n",
    "    )\n",
    "    val_dataset = datasets.Infra_dataset(train=False,class_nums = class_nums,self_train=False,transform=val_transform,file_root = file_root,fold=fold)\n",
    "    val_data_loader = data_utils.DataLoader(val_dataset, batch_size=BATCH_SIZE//2, shuffle=True, num_workers=num_workers//2,collate_fn=custum_collate, pin_memory=True, drop_last=True)\n",
    "\n",
    "    #Model Create\n",
    "\n",
    "    exp = Exp(class_nums = class_nums)\n",
    "    model = exp.get_model()\n",
    "\n",
    "    #ckpt = torch.load('/home/etri/road-dataset/Track_YOLOX/last.ckpt')\n",
    "    #model = utility.load_my_state_dict(model,ckpt[\"state_dict\"],legacy=True)\n",
    "    \n",
    "    #ckpt = torch.load('/home/etri/road-dataset/Mask_YOLOX/yolox_l.pth', map_location='cpu')\n",
    "    #model = utility.load_my_state_dict(model,ckpt[\"model\"])\n",
    "    \n",
    "    ckpt = torch.load('./output/2023-09-27-14-32-48_val/checkpoints/last.pth.tar', map_location='cpu')\n",
    "    model = utility.load_my_state_dict(model,ckpt[\"state_dict\"])\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=0)\n",
    "    scheduler = utility.CosineAnnealingWarmUpRestarts(optimizer, T_0=T_0, T_mult=T_mult, eta_max=eta_max,  T_up=T_up, gamma=gamma)\n",
    "    #model.cuda()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "      # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "      model = nn.DataParallel(model)\n",
    "    \n",
    "    model.to(device)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    #Save Path Creation\n",
    "    now = datetime.datetime.now()\n",
    "    output_dir = f'./output/{now.strftime(\"%Y-%m-%d-%H-%M-%S\")}'+purpose\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    checkpoint_dir = os.path.join(output_dir, 'checkpoints')\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=os.path.join(output_dir, 'logs'))\n",
    "    copyfile('./yolox/models/yolo_head.py', output_dir + '/'  + \"yolo_head.py\")\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "\n",
    "  \n",
    "        model.train()\n",
    "\n",
    "        print('training_start : ', epoch)\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (img,mask, box,cls,_,_) in enumerate(train_data_loader):\n",
    "            #try:\n",
    "            img,mask, box,cls =  img.cuda(non_blocking=True),mask.cuda(non_blocking=True), box.cuda(non_blocking=True),cls.cuda(non_blocking=True)\n",
    "            #print(box)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                result = model(img,mask, box,cls)\n",
    "                loss = result['total_loss']\n",
    "            scaler.scale(torch.sum(loss)).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Log training statistics to TensorBoard\n",
    "            n_iter = epoch * len(train_data_loader) + batch_idx\n",
    "            writer.add_scalar('Train/Loss', torch.sum(result['total_loss']).item(), n_iter)\n",
    "            writer.add_scalar('Train_Loss/Loss_reid', torch.sum(result['reid_loss']).item(), n_iter)\n",
    "            writer.add_scalar('Train_Loss/Loss_iou',torch.sum(result['iou_loss']).item(), n_iter)\n",
    "            writer.add_scalar('Train_Loss/Loss_conf', torch.sum(result['conf_loss']).item(), n_iter)\n",
    "            writer.add_scalar('Train_Loss/Loss_cls', torch.sum(result['cls_loss']).item(), n_iter)\n",
    "            writer.add_scalar('Train_Loss/Loss_contra', torch.sum(result['contra_loss']).item(), n_iter)\n",
    "\n",
    "            #except:\n",
    "            #    print(mimages.shape, fimages.shape,bimages.shape, boxes, labels)\n",
    "\n",
    "        scheduler.step()    \n",
    "        writer.add_scalar('Train/Learning_rate', scheduler.get_lr()[0], epoch)\n",
    "\n",
    "        print('training_end : ', epoch)\n",
    "        end_time = time.time()\n",
    "        print('Time elapse: ', end_time-start_time)\n",
    "\n",
    "        if epoch%5>0:\n",
    "            continue\n",
    "        \n",
    "        print('Validation_start : ', epoch)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        det_boxes = []\n",
    "               \n",
    "        gt_boxes_all = []\n",
    "        num_instance = 0\n",
    "        num_success_fifty = 0\n",
    "        num_success_ninety = 0\n",
    "        \n",
    "        for _ in range(len_class):\n",
    "            det_boxes.append([])\n",
    "            \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (img,mask, box,cls,_,_) in enumerate(val_data_loader):\n",
    "                #try:\n",
    "                img,mask, box,cls =  img.cuda(non_blocking=True),mask.cuda(non_blocking=True), box.cuda(non_blocking=True),cls.cuda(non_blocking=True)\n",
    "                #print(box.shape,cls.shape)\n",
    "                mask = torch.nn.functional.interpolate(mask.unsqueeze(1),size=(mask.shape[1]//4,mask.shape[2]//4),\n",
    "                                                     mode='nearest-exact').squeeze(1)\n",
    "                \n",
    "                output = model(img)\n",
    "                result,re_mask,bg_vector = output['results'],output['mask_output'],output['bg_vector']\n",
    "                #print(result.shape)\n",
    "                outputs = utility.val_postprocess(result, len_class, 0.1,0.5)\n",
    "\n",
    "                for b in range(len(outputs)):\n",
    "                    if b%2==0:\n",
    "                        #print(len(det_boxes))\n",
    "                        #print(len(gt_boxes_all))\n",
    "                        if outputs[b]==None:\n",
    "                            pass\n",
    "                        else:\n",
    "                            outputs_batch = outputs[b].cpu().numpy()\n",
    "                            box_batch = box[b].cpu().numpy()\n",
    "                            cls_batch = cls[b].cpu().numpy()[:,:len_class]\n",
    "\n",
    "\n",
    "                            frame_gt = utility.get_individual_labels(box_batch, cls_batch)\n",
    "                            #print(\"Step_End:\",outputs_batch.astype('int'))\n",
    "                            #print(frame_gt)\n",
    "                            gt_boxes_all.append(frame_gt)\n",
    "\n",
    "                            nframe_gt = utility.get_individual_labels(box_batch, cls_batch[:,:7])\n",
    "\n",
    "                            pair_box = utility.pair_boxes(nframe_gt,outputs_batch[:,:6])\n",
    "\n",
    "\n",
    "                            for cl_ind in range(len_class):\n",
    "                                new_target = outputs_batch[outputs_batch[:,7+cl_ind]==1]\n",
    "                                new_outputs = np.zeros((new_target.shape[0], 5))\n",
    "                                new_outputs[:,0:4] = new_target[:,0:4]\n",
    "                                new_outputs[:,4] =new_target[:,4]*new_target[:,5]\n",
    "                                det_boxes[cl_ind].append(new_outputs)\n",
    "\n",
    "\n",
    "                            iouEvalVal = utility.iouEval(nframe_gt.shape[0]+1)\n",
    "\n",
    "                            target_mask = re_mask[b,:,:,:]      \n",
    "                            target_vec = F.normalize(torch.cat((outputs[b][:,-256:],bg_vector[b].unsqueeze(0)),dim=0),p=2,dim=1)\n",
    "\n",
    "                            semseg = torch.einsum(\"cq,qhw->chw\", target_vec, target_mask)\n",
    "\n",
    "                            max_val, max_idx= torch.max(semseg,0)\n",
    "\n",
    "                            target_mask = torch.zeros_like(max_idx)\n",
    "                            for gt, target in pair_box:\n",
    "                                target_mask[max_idx==target]=gt+1\n",
    "\n",
    "                            iouEvalVal.addBatch(target_mask.unsqueeze(0).unsqueeze(0).to(torch.long), mask[b].unsqueeze(0).unsqueeze(0).to(torch.long))\n",
    "\n",
    "                            iouTrain, iou_classes = iouEvalVal.getIoU()\n",
    "                            #print(iouTrain, iou_classes)\n",
    "                            num_instance += len(iou_classes)\n",
    "                            num_success_fifty += len(iou_classes[iou_classes>0.5])\n",
    "                            num_success_ninety += len(iou_classes[iou_classes>0.9])\n",
    "                            #print(num_instance, num_success)\n",
    "                \n",
    "        \n",
    "\n",
    "            #mAP, ap_all = evaluate.evaluate(gt_boxes_all,det_boxes, all_classes, iou_thresh=0.5)\n",
    "\n",
    "            mAP, ap_all = evaluate.evaluate(gt_boxes_all,det_boxes, all_classes, iou_thresh=0.5)\n",
    "            print(mAP, num_success_fifty/(num_instance+0.1), num_success_ninety/(num_instance+0.1))\n",
    "            print(ap_all)\n",
    "\n",
    "            writer.add_scalar('Val/Accuracy50', num_success_fifty/(num_instance+0.1), epoch)\n",
    "            writer.add_scalar('Val/Accuracy90', num_success_ninety/(num_instance+0.1), epoch)\n",
    "            writer.add_scalar('Val/mAP', mAP[0], epoch)\n",
    "\n",
    "        accuracy = num_success_fifty/(num_instance+0.1)\n",
    "        \n",
    "        is_best = best_acc<accuracy\n",
    "        if is_best:\n",
    "            best_acc = accuracy\n",
    "            print('Best: ', accuracy)\n",
    "        last_PATH = checkpoint_dir+'/last.pth.tar'\n",
    "        best_PATH = checkpoint_dir+'/best.pth.tar'\n",
    "        utility.save_checkpoint({\n",
    "            'epoch': epoch+1,\n",
    "            'arch': str(model),\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "            #'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, last_PATH, best_PATH)\n",
    "\n",
    "\n",
    "        print('Val_end : ', epoch)\n",
    "        end_time = time.time()\n",
    "        print('Time elapse: ', end_time-start_time)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f8f2a-727e-4f35-b297-9a775f07b161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
